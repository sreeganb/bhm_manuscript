%Version 3.1 December 2024
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%=========================================================================================%%
%% the documentclass is set to pdflatex as default. You can delete it if not appropriate.  %%
%%=========================================================================================%%

%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-chicago.bst%  
 
%%\documentclass[pdflatex,sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style
%%\documentclass[pdflatex,sn-mathphys-ay]{sn-jnl}% Math and Physical Sciences Author Year Reference Style
%%\documentclass[pdflatex,sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[pdflatex,sn-vancouver-num]{sn-jnl}% Vancouver Numbered Reference Style
%%\documentclass[pdflatex,sn-vancouver-ay]{sn-jnl}% Vancouver Author Year Reference Style
%%\documentclass[pdflatex,sn-apa]{sn-jnl}% APA Reference Style
%%\documentclass[pdflatex,sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{tikz}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{tikz-3dplot}%
\usepackage{pgf}
\usetikzlibrary{positioning}
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers

% Define custom color for your comments
\definecolor{sreegreen}{RGB}{0,128,0}  % Forest green color

% Create \sree command with colored text
\newcommand{\sree}[1]{%
    \textcolor{sreegreen}{#1}%
}

\definecolor{ignacia}{RGB}{120,0,0}

\newcommand{\ignacia}[1]{%
    \textcolor{ignacia} {#1}% 
}

%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[BHM]{Bayesian Hierarchical Modeling for Protein Complex Assembly}

%%=============================================================%%
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% \author*[1,2]{\fnm{Joergen W.} \spfx{van der} \sur{Ploeg} 
%%  \sfx{IV}}\email{iauthor@gmail.com}
%%=============================================================%%

\author[1]{\fnm{Sree ganesh} \sur{Balasubramani}}\email{sreeuci@gmail.com}

\author*[2]{\fnm{Ignacia} \sur{Echeverria}}\email{Ignacia.EcheverriaRiesco@ucsf.edu}
%\equalcont{These authors contributed equally to this work.}

\affil[1]{\orgdiv{Quantitative biosciences institute}, \orgname{University of California}, \orgaddress{\street{Street}, \city{San Francisco}, \postcode{94158}, \state{California}, \country{USA}}}

\affil*[2]{\orgdiv{School of Pharmacy}, \orgname{University of California}, \orgaddress{\street{600 16th Street, #S472}, \city{San Francisco}, \postcode{94158}, \state{California}, \country{USA}}}

%%==================================%%
%% Sample for unstructured abstract %%
%%==================================%%
\abstract{In this document, we describe a Bayesian hierarchical modeling framework to assemble protein 
complexes using experimental data, such as crosslinking mass spectrometry and cryo-electron 
microscopy (cryo-EM). This approach exploits the hierarchical nature of protein complex assembly 
and integrates multiple data sources to infer the spatial structure of the complex. 
We elaborate on the mathematical formulation and illustrate the method 
with a toy model problem based on distance restraints. Furthermore, we demonstrate the applicability 
of this method for protein complex assemblies such as the postsynaptic density (PSD).

\keywords{Bayesian hierarchical modeling, }

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}\label{sec1}

(Challenge of determining structures of non-homogeneous protein assemblies that lack regular or symmetrical organization) Structural determination of large, non-homogeneous protein assemblies remains a significant challenge in structural biology despite recent advances in experimental techniques. These assemblies, characterized by compositional variability represented as variable stoichiometries and conformational heterogeneity, often resist crystallization and lack the symmetry required for single-particle cryo-electron microscopy analysis \cite{Topf08Structure16p295} (CITE). However, many of these assemblies perform essential cellular functions through dynamic rearrangements of their components and have modular architectures with multiple copies of the same protein occurring in similar contexts (CITE). \cite{Boeckers06CellandTissuep409,Devos06PNAS103p2172} Some examples include the nuclear pore complex \cite{Alber07Nature450p695}, clathrin-coated vesicles \cite{Devos04PLOSBiology2p380}, DNA damage response foci \cite{Polo11GenesDev25p409}, and focal adhesions \cite{Geiger01NatRevMolCellBiol2p793,Mishra21CellSignal85p110046}.

(Current structural biology techniques and their limitations when applied to heterogeneous protein assemblies) \ignacia{Alternative approaches to traditional structural biology methods include} integrative/hybrid structure modeling 9–11, which are robust and complementary tools for determining the structures of protein assemblies. These methods combine information from multiple sources, including experiments, computational predictions, and biophysical considerations, to generate structural models that satisfy all available information within their respective uncertainties. More recently, integrative structure models can also incorporate models obtained using deep-learning approaches such as structure predictions \cite{Stahl23NatBiotechnol41p1810} (CITE), MUSIC, and XX. However, integrative methods often struggle with assemblies that exhibit variability in stoichiometry or contain large regions of intrinsic disorder.  

(Bayesian Hierarchical Modeling (BHM) as a novel approach for elucidating the structure of complex protein assemblies) We propose Bayesian Hierarchical Modeling (BHM) as a natural extension of current integrative structure modeling approaches by formalizing protein assemblies as nested probabilistic structures with explicit dependencies between organizational levels. While integrative methods have made progress in combining multiple data types, BHM offers a statistical framework to represent the inherently hierarchical nature of protein complexes—from domains to subunits to subcomplexes to complete assemblies. The key innovation of BHM lies in its treatment of repeating structural motifs through shared parametric distributions and its ability to propagate uncertainty between levels through conditional probabilities. Similarly to IM, by modeling component positions and orientations as distributions rather than point estimates, BHM captures structural heterogeneity at each hierarchical level and leverages Markov Chain Monte Carlo sampling to generate structural ensembles that quantitatively represent both the most probable configurations and the confidence in these predictions, providing insights even when traditional methods fail due to flexibility or compositional heterogeneity.

(Explanation of how BHM can integrate diverse types of structural data to generate models of heterogeneous assemblies) The multi-level architecture of BHM provides specific advantages for integrating diverse sources of data and input information by matching each data or information type to its appropriate hierarchical level. High-resolution atomic structures inform domain-level priors, while crosslinking mass spectrometry data constrain the relative positions of interacting components through distance restraints in the likelihood function. Cryo-EM density maps guide the overall shape at higher organizational levels, with lower-resolution regions appropriately weighted according to their uncertainty. This hierarchical organization allows BHM to handle mixed-resolution data naturally—precise atomic coordinates for well-structured domains can coexist with diffuse probability clouds for flexible regions. Furthermore, BHM excels at incorporating population-level data from techniques like SAXS or ion mobility mass spectrometry by treating them as ensemble averages rather than constraints on individual structures. The Bayesian framework also enables the rational inclusion of prior knowledge about protein interactions, interface preferences, and excluded volume, with the posterior distributions revealing which structural features are well-determined by the data versus those that remain ambiguous. 
,  making it necessary to characterize them in their native cellular environment

(Overview of the paper structure) In this paper, we first describe the mathematical foundation of our BHM approach and how it represents protein assemblies as nested probabilistic structures with defined dependencies between organizational levels. We describe the details of our approach, including model representation, formulation of data likelihoods and priors to integrate diverse sources of information, Markov Chain Monte Carlo sampling implementation, and model validation and assessment strategies. Next, we demonstrate the method's capabilities through application to a toy model system inspired by the nuclear pore complex. We show how the approach recovers the correct architecture despite limited information, and that we make no assumptions regarding the system symmetry. We then discuss how this framework can be extended to other heterogeneous biological assemblies and how different data types could be used for BHM. Finally, we highlight how this method complements existing structural biology techniques and might enable new insights into the organization of complex cellular machinery.

\section{Methods}\label{sec2}
\subsection{Bayesian hierarchical model formulation}
The Bayesian approach \cite{Rieping05Science309p303} estimates the probability of a model, given information available about the system, including both prior knowledge and newly acquired experimental data. The model $M=(X,\{\alpha_i\})$ includes the structure coordinates $X$ and additional parameters $\{\alpha_i\}$ (below). Using Bayes’ theorem, the posterior probability $P(M|D,I)$, given data $D$ and prior knowledge $I$, is
 
\begin{equation}
    p(M|D,I) \propto p(D|M,I) \cdot p(M|I)
\end{equation}

where the likelihood function $p(D|M,I)$ is the probability
of observing the data $D$ given $I$ and $M$ and $p(M|I)$ that is independent of the data is called the prior distribution. 

Bayesian inference provides a powerful framework for integrating prior knowledge with experimental data, making it a valuable tool for estimating model parameters under uncertainty. In structural biology, this approach excels by combining diverse data sources—such as X-ray crystallography, cryo-electron microscopy, and nuclear magnetic resonance—to enhance our understanding of complex molecular systems. Despite its strengths, the standard Bayesian approach may encounter significant limitations when applied to the determination of structures for large and heterogeneous protein complexes, particularly when the experimental data $D$ are sparse, noisy and collected from multiple sources with varying levels of precision and precision. In such cases, the high dimensionality of the structural coordinates $X$ and the additional parameters $\{\alpha_i\}$ in the model $M=(X,\{\alpha_i\})$ can lead to a posterior distribution $p(M|D,I)$ that remains poorly constrained by the limited data. The sparsity of $D$ implies that the likelihood function $p(D|M,I)$ may lack sufficient information to effectively update the prior $p(M|I)$, resulting in substantial uncertainty in the estimated structure. Furthermore, the heterogeneity of the data sources complicates the construction of a unified likelihood function, as it may fail to adequately reflect the differing reliabilities and precisions inherent to each experimental measurement, potentially leading to biased or inefficient inference.

To address these challenges, hierarchical Bayesian modeling emerges as a necessary and more robust framework by structuring the prior distribution $p(M|I)$ in a multi-level manner. In this approach, hyperparameters are introduced to govern the distributions of lower-level parameters, such as those specific to each experimental dataset (e.g., noise characteristics or biases), which can be modeled as being drawn from a shared distribution. This hierarchical structure allows the model to pool information across diverse data sources while accounting for their individual properties, thereby improving the accuracy and efficiency of the inference process. Moreover, hierarchical priors can be tailored to capture the multi-scale organization of protein structures, incorporating prior knowledge at various levels---from atomic coordinates $X$ to higher-order structural features---thus reflecting the inherent complexity of the system. Consequently, hierarchical Bayesian inference provides a powerful methodology to integrate sparse and noisy experimental data, enabling more reliable determination of the structures of complex protein assemblies.

In hierarchical Bayesian modeling, the prior distribution \( p(M|I) \) for the model \( M = (X, \{\alpha_i\}) \) is structured hierarchically by introducing hyperparameters \(\theta\). These hyperparameters govern the distribution of the model parameters \(\{\alpha_i\}\). The prior can be decomposed as follows:

\[
p(M|I) = p(X, \{\alpha_i\} | I) = p(X | \{\alpha_i\}, I) \cdot p(\{\alpha_i\} | \theta, I) \cdot p(\theta | I)
\]

This decomposition allows the model to share information across the parameters \(\{\alpha_i\}\) through \(\theta\), a hallmark of hierarchical modeling. Here, \( p(X | \{\alpha_i\}, I) \) represents the prior distribution over the structural coordinates \( X \), which may depend on the parameters \(\{\alpha_i\}\). The term \( p(\{\alpha_i\} | \theta, I) \) is the conditional prior for the parameters \(\{\alpha_i\}\), governed by the hyperparameters \(\theta\), and \( p(\theta | I) \) is the hyperprior, encoding prior knowledge about \(\theta\).

The likelihood function \( p(D | M, I) \) reflects the hierarchical structure by modeling the data \( D \) as a collection of datasets \( D = \{D_j\} \), each associated with its own parameter \(\alpha_j\). The likelihood can be written as:

\[
p(D | M, I) = \prod_j p(D_j | X, \alpha_j, I)
\]

where \( D_j \) denotes a subset of the data (e.g., observations related to a specific protein or experimental condition), and \( p(D_j | X, \alpha_j, I) \) is the likelihood of the data \( D_j \) given the shared structural coordinates \( X \) and the specific parameter \(\alpha_j\). The product \(\prod_j\) assumes conditional independence of the datasets given the model parameters, allowing each \( D_j \) to be influenced by both the global structure \( X \) and local parameters \(\alpha_j\).

The posterior distribution \( p(M | D, I) \) combines the hierarchical prior and the likelihood using Bayes' theorem. It is expressed as:

\[
p(X, \{\alpha_i\}, \theta | D, I) \propto p(D | X, \{\alpha_i\}, I) \cdot p(X | \{\alpha_i\}, I) \cdot p(\{\alpha_i\} | \theta, I) \cdot p(\theta | I)
\]

This posterior jointly estimates \( X \), \(\{\alpha_i\}\), and \(\theta\), enabling the model to learn from the data at multiple levels: the global structure (\( X \)), the individual parameters (\(\{\alpha_i\}\)), and the hyperparameters (\(\theta\)). Here, \( p(D | X, \{\alpha_i\}, I) \) is the likelihood of the full dataset \( D \), which can be expanded as \(\prod_j p(D_j | X, \alpha_j, I)\), while the remaining terms come from the hierarchical prior.

%A hierarchical Bayesian model is defined as a Bayesian statistical model where the 
%prior distribution $p(M|I)$ is expressed as a product of conditional distributions given by
%\begin{equation}
%p(M|I) = \int p_1(M|M_1,I)p_2(M_1|M2,I)\ldots p_{n+1}%(M_n|I)dM_1\ldots dM_n.
%\end{equation}
%Here $M$ represents the parameters of primary interest and $\{M_1, M_2\ldots,M_n\}$
%are called as hyperparameters at successive levels, each conditioning the distribution of the parameters below it. This decomposition reflects a multi-level dependency structure, where each level introduces additional flexibility and incorporates prior knowledge or constraints at different scales. The marginal distribution $p_{n+1}(M_n|I)$ serves as the top level prior, anchoring the hierarchy.

%In the general case, this structure allows the model to capture complex relationships by breaking them into manageable conditional dependencies. For instance, $M$ might represent the quantities we aim to infer directly from the data $D$, with its distribution $p_1(M|M_1,I)$ governed by the hyperparameters $M_1$ which
%in turn depends on $M_2$ via $p_2(M_1|M_2,I)$ and so forth up to $M_n$. The full joint distribution is given by
%\begin{equation}
%p(M,M_1,M_2,\ldots, M_n|I) = p_1(M|M_1,I)p_2(M_1|M2,I)\ldots p_{n+1}(M_n|I)
%\end{equation}
%and the posterior, incorporating the data then becomes
%\begin{equation}
%    p(M,M_1,M_2,\ldots, M_n|D,I) \propto p(M|D,I)p_1(M|M_1,I)\ldots p_{n}(M_{n-1}|M_n,I)p_{n+1}(M_n|I) \qquad
%\end{equation}
%This formulation enables inference across all levels simultaneously, balancing data-driven evidence with structured prior beliefs.
%\newline

\subsection{Representation of the hierarchical structure}
\begin{tikzpicture}[
  node distance=1.5cm and 2cm,  % Vertical and horizontal spacing
  hyperparam/.style={circle, draw, fill=blue!10, minimum size=1cm, font=\normalsize},
  structure/.style={circle, draw, fill=red!10, minimum size=1cm, font=\normalsize},
  parameter/.style={circle, draw, fill=green!10, minimum size=1cm, font=\normalsize},
  data_dense/.style={rectangle, draw, fill=gray!20, minimum size=1cm, font=\normalsize},
  data_sparse/.style={rectangle, draw=dashed, fill=gray!20, minimum size=1cm, font=\normalsize},
  arrow/.style={->, thick},
  label/.style={font=\small}
]

% Structural states (X1, X2, X3) at the top
\node[structure] (X1) {$X_1$};
\node[structure, right=2cm of X1] (X2) {$X_2$};
\node[structure, right=2cm of X2] (X3) {$X_3$};

% Hyperparameter node
\node[hyperparam, above=1.5cm of X2] (theta) {$\theta$};

% Experiment-specific parameter nodes
\node[parameter, below left=1.5cm and 1cm of X1] (alpha1) {$\alpha_1$};
\node[parameter, below=1.5cm of X2] (alpha2) {$\alpha_2$};
\node[parameter, below right=1.5cm and 1cm of X3] (alpha3) {$\alpha_3$};

% Dataset nodes
\node[data_dense, below=1.5cm of alpha1] (D1) {$D_1$};
\node[data_sparse, below=1.5cm of alpha2] (D2) {$D_2$};
\node[data_dense, below=1.5cm of alpha3] (D3) {$D_3$};

% Arrows from hyperparameter to experiment-specific parameters
\draw[arrow] (theta) -- (alpha1);
\draw[arrow] (theta) -- (alpha2);
\draw[arrow] (theta) -- (alpha3);

% Arrows from structural states to datasets
\draw[arrow] (X1) -- (D1);
\draw[arrow] (X2) -- (D2);
\draw[arrow] (X3) -- (D3);

% Arrows from experiment-specific parameters to datasets
\draw[arrow] (alpha1) -- (D1);
\draw[arrow] (alpha2) -- (D2);
\draw[arrow] (alpha3) -- (D3);

% Labels for clarity
\node[label, above=0.1cm of X2] {structural states (inferred)};
\node[label, above=0.1cm of theta] {hyperparameter};
\node[label, left=0.1cm of alpha1] {experiment params};
\node[label, below=0.1cm of D1] {dense};
\node[label, below=0.1cm of D2] {sparse};
\node[label, below=0.1cm of D3] {dense};

\end{tikzpicture}


(Representation of the hierarchical structure)
(Definition of prior distributions at each level)
(Specification of conditional dependencies between levels)

\subsection{Model representation, spatial restraints, and prior distributions
}
(Formulation of likelihood functions for different data types)
(Priors)
(Treatment of repeating structural motifs)
(Treatment of localization information)
(Treatment of spatial relationships)


\subsection{Model Sampling}
(sampling strategies)

\subsection{Analysis and validation}
(Convergence criteria and assessment)
(Ensemble analysis approaches)
\ignacia{Illustration: Nuclear pore complex inspired toy model (add figure)}
%------------------------------------------------
\subsubsection{Description of the toy model system}

Input information
Model representation and spatial restraints

The toy model problem consists of three types of particles 
A, B and C with copy numbers given by $N_A=8$, $N_B=8$ and $N_C=16$,
respectively. The input information consists of a noisy measurement 
of the pairwise distances between particles $A-A$, $A-B$ and $B-C$
with associated standard deviations treated as parameters, 
$\sigma_{AA}$, $\sigma_{AB}$ and $\sigma_{BC}$.
The ideal ground truth structure 
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/ideal_structure.pdf}
    \caption{Ideal ground truth structure for the toy model problem with 
    particles A, B and C being colored red, blue and green, respectively.}
    \label{fig:enter-label}
\end{figure}
\section{Results}

\subsection{Comparison with traditional integrative modeling}
\begin{itemize}
\item TODO: Create the toy model problem within IMP and use two different kinds of restraints:
the first, add the best score pair distance restraints, the second, add all vs all pair distance 
restraints.
\end{itemize}
(Scoring analysis)

(Convergence analysis)
(Model analysis)

Sensitivity to hyperparameter choices
(Structural analysis)
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/combined_kde_plots.pdf}
    \caption{Evolution of the $\sigma$ parameters as a function of the sampler sequence}
    \label{fig:enter-label}
\end{figure}
Analysis of structural variability among repeated elements
Advantages of BHM over treating each instance independently
Recovery of structural patterns with limited data

\section{Discussion}
(Summary of key advances) This work addresses a critical gap in structural biology by introducing a framework for integrative structure modeling of protein assemblies with compositional variability and conformational heterogeneity. By implementing a hierarchical Bayesian approach, we provide a probabilistic representation that naturally accommodates the multi-scale organization and inherent heterogeneity of complex protein assemblies. Our method explicitly models repeating structural motifs and variable stoichiometries, enabling the structural characterization of assemblies like the nuclear pore complex where symmetry is incomplete and composition varies. Unlike methods that require homogeneous samples or impose rigid constraints, our approach embraces structural diversity by producing ensembles that quantify uncertainty and capture conformational variability. This framework therefore extends the reach of structural biology into previously inaccessible regimes of macromolecular organization where function emerges from dynamic interactions rather than static arrangements.

These assemblies might exhibit variable stoichiometry, the presence of conformational heterogeneity of their components, and transient interactions with binding partners. 

\subsection{(Biologically relevant applications)}

(Cryo-ET)
(Genetic interaction mapping): Genetic interactions report how the effect of one mutation is affected by the presence of a second mutation. These relationships are often used to identify functional relationships among genes, including biological pathways24–26 and protein complexes.27–29 Two examples include point-mutant epistatic miniarray profile (pE-MAP)30,31 and deep mutational scanning (DMS).32 Similar to residue coevolution analysis that uses correlated sequence variations to model proteins and their complexes,33–36 quantitative measurements of genetic interactions be used for structural modeling.12,13,15 In contrast to coevolution methods that use natural sequence variation that sparsely samples the sequence landscape under a variety of selection pressures, high-throughput genetic perturbation experiments characterize the sequence-function landscape under controlled experimental conditions. However, critical challenges of interpreting genetics interaction data include disentangling direct and indirect relationships between residue positions34,37 and inferring the roles of conformational heterogeneity and allostery.38,39 

(In vivo qXL-MS): In XL-MS, protein complexes are covalently stabilized by cross-linkers and digested, followed by identification of the cross-linked peptides by mass spectrometry (MS).21 XL-MS has proven effective in mapping protein-protein interactions (PPIs) in vitro and in vivo and providing structural information for integrative/hybrid modeling. Additionally, qXL-MS enables dissenting the structural dynamics of protein assemblies and performing comparative analysis under different conditions, which, in turn, allows assessing condition-dependent structural changes. Additionally, strategies that couple in vivo qXL-MS with isotope labeling have been to identify novel protein assemblies, determining their interaction dynamics, and distinguishing transients from stable interactions.40,41 However, critical challenges in interpreting in vivo qXL-MS data include the inherent compositional and structural heterogeneity of the samples and ambiguity associated with assigning cross-linked peptides to specific components.

(AI): Recent advances in deep-learning have revolutionized protein structure prediction; for example, AlphaFold (AF)1 and RoseTTAfold2 can often produce models with atomic accuracies comparable to those of experimental methods.3,4 However, in general, these AI-based approaches generate single structures rather than structural ensembles, do not capture the conformational mechanisms like allostery,5 do not describe the conformational ensembles of intrinsically disordered regions,6 and have limited capabilities describing the structures of large protein complexes.7,8 

(Methodological limitations) Having to define the levels, data sparseness, and same protein occurring in different contexts 

(Future directions)

(Advantages of using in vivo/in situ data) Moreover, traditional structural biology methods often rely on purified samples and describe one or few conformers. 


\backmatter

\bmhead{Supplementary information}

If your article has accompanying supplementary file/s please state so here. 

Authors reporting data from electrophoretic gels and blots should supply the full unprocessed scans for key as part of their Supplementary information. This may be requested by the editorial team/s if it is missing.

Please refer to Journal-level guidance for any specific requirements.

\bmhead{Acknowledgements}

Acknowledgements are not compulsory. Where included they should be brief. Grant or contribution numbers may be acknowledged.

Please refer to Journal-level guidance for any specific requirements.

\section*{Declarations}

Some journals require declarations to be submitted in a standardised format. Please check the Instructions for Authors of the journal to which you are submitting to see if you need to complete this section. If yes, your manuscript must contain the following sections under the heading `Declarations':

\begin{itemize}
\item Funding
\item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
\item Ethics approval and consent to participate
\item Consent for publication
\item Data availability 
\item Materials availability
\item Code availability 
\item Author contribution
\end{itemize}


\begin{appendices}

\section{Section title of first appendix}\label{secA1}

An appendix contains supplementary information that is not an essential part of the text itself but which may be helpful in providing a more comprehensive understanding of the research problem or it is information that is too cumbersome to be included in the body of the paper.

%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

\end{appendices}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%
% --- Bibliography ---
\bibliographystyle{nature} % Sets the bibliography style (e.g., plain, unsrt, apalike)
\bibliography{manuscript}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl

\end{document}
